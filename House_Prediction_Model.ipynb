{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "691d1a9f",
   "metadata": {},
   "source": [
    "## Data Preparation & Exploration\n",
    "The first step in any machine learning project is to understand and prepare the data. Here, we load the dataset from houses_Madrid.csv and perform an initial exploration.\n",
    "\n",
    "The scatter plot gives us a visual confirmation that there appears to be a positive linear relationship between the square meters of a property and its price as the size increases, the price tends to increase as well. This makes it a good candidate for a linear regression model.\n",
    "\n",
    "Finally, we split the data into a training set (first 16,000 samples) and a test set (remaining samples).\n",
    "\n",
    "Why do we do this? This separation is crucial. We use the training set to teach our model the relationship between size and price. The test set, which the model has never seen, is then used to evaluate how well the model generalizes to new, unseen data. This gives us an honest assessment of its performance and helps prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "902ccefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       sq_mt_built  n_rooms  n_bathrooms  built_year  rent_price  \\\n",
      "4              108        2            2        2003        1094   \n",
      "28              65        3            1        1976         744   \n",
      "31             123        3            2        2002        1195   \n",
      "40             125        3            3        2004        1135   \n",
      "45              83        2            2        2020        1004   \n",
      "...            ...      ...          ...         ...         ...   \n",
      "21719          161        4            2        1974        1816   \n",
      "21724          102        2            2        1976        1187   \n",
      "21732           74        2            1        1988        1037   \n",
      "21738           96        2            2        2002        1496   \n",
      "21739          175        4            2        2002        2081   \n",
      "\n",
      "       has_lift_True  has_parking_True  is_renewal_needed_True  \\\n",
      "4                  1                 1                       0   \n",
      "28                 1                 0                       1   \n",
      "31                 1                 1                       0   \n",
      "40                 1                 0                       0   \n",
      "45                 1                 1                       0   \n",
      "...              ...               ...                     ...   \n",
      "21719              1                 1                       0   \n",
      "21724              1                 0                       0   \n",
      "21732              1                 1                       0   \n",
      "21738              1                 1                       0   \n",
      "21739              0                 1                       0   \n",
      "\n",
      "       is_exterior_True  floor_2  floor_3  floor_4  floor_5  floor_6  floor_7  \\\n",
      "4                     1        0        0        1        0        0        0   \n",
      "28                    1        0        0        0        0        0        0   \n",
      "31                    1        0        0        0        0        0        1   \n",
      "40                    1        0        0        0        0        0        1   \n",
      "45                    1        0        0        0        0        0        1   \n",
      "...                 ...      ...      ...      ...      ...      ...      ...   \n",
      "21719                 1        0        1        0        0        0        0   \n",
      "21724                 1        0        0        0        0        0        0   \n",
      "21732                 1        0        0        0        0        0        0   \n",
      "21738                 1        0        1        0        0        0        0   \n",
      "21739                 1        0        0        0        0        0        0   \n",
      "\n",
      "       floor_8  floor_9  floor_Bajo  floor_Entreplanta exterior  \n",
      "4            0        0           0                           0  \n",
      "28           0        0           0                           0  \n",
      "31           0        0           0                           0  \n",
      "40           0        0           0                           0  \n",
      "45           0        0           0                           0  \n",
      "...        ...      ...         ...                         ...  \n",
      "21719        0        0           0                           0  \n",
      "21724        0        0           0                           0  \n",
      "21732        0        0           0                           1  \n",
      "21738        0        0           0                           0  \n",
      "21739        0        0           1                           0  \n",
      "\n",
      "[1593 rows x 19 columns]\n",
      "Training set shape: (1274, 19)\n",
      "Test set shape: (319, 19)\n",
      "Root Mean Squared Error (RMSE): 272,170.87\n",
      "R-squared (R²): 0.7540\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import sklearn as sk\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set a random seed for reproducibility of results\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load the dataset from a CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(\"houses_Madrid.csv\")\n",
    "features = [\n",
    "    'sq_mt_built',\n",
    "    'n_rooms',\n",
    "    'n_bathrooms',\n",
    "    'built_year',\n",
    "    'has_lift',\n",
    "    'has_pool',\n",
    "    'has_parking',\n",
    "    'is_new_development',\n",
    "    'is_renewal_needed',\n",
    "    'floor',\n",
    "    'rent_price',\n",
    "    'is_exterior',\n",
    "    'buy_price'\n",
    "]\n",
    "\n",
    "df_dropped = df[features].dropna()\n",
    "\n",
    "cat = ['has_lift', 'has_pool', 'has_parking', 'is_new_development',\n",
    "    'is_renewal_needed', 'is_exterior', 'floor']\n",
    "\n",
    "num = ['sq_mt_built', 'n_rooms', 'n_bathrooms', 'rent_price']\n",
    "\n",
    "one_hot_df = pd.get_dummies(df_dropped, columns = cat, drop_first=True).astype(int)\n",
    "# print(one_hot_df.head())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for item in features:\n",
    "#     print(df[item].head())\n",
    "\n",
    "#proccess the floors categorical variables into numeric\n",
    "#print(df_dropped['floor'].unique())\n",
    "\n",
    "\n",
    "# df_dropped['floor'] = df_dropped['floor'].replace(floor_mapping)\n",
    "\n",
    "# drop rows with missing values in the selected features\n",
    "# dropped 2992 rows\n",
    "\n",
    "\n",
    "\n",
    "# convert has_lift to numeric\n",
    "# df_dropped['has_lift'] = df_dropped['has_lift'].replace(True, 1)\n",
    "# df_dropped['has_lift'] = df_dropped['has_lift'].replace(False, 0)\n",
    "\n",
    "\n",
    "\n",
    "# for item in features:\n",
    "#     print(df_dropped[item].head())\n",
    "\n",
    "X = one_hot_df.drop(columns=['buy_price'])\n",
    "y = df_dropped['buy_price']\n",
    "print(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "\n",
    "\n",
    "# # # 1. Initialize the model\n",
    "model = LinearRegression()\n",
    "\n",
    "# # \n",
    "# 2. Train the model using your training data\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# # 4. Calculate the performance metrics by comparing actual values (y_test) to predicted values (y_pred)\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:,.2f}\")\n",
    "print(f\"R-squared (R²): {r2:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#encode categorical features and truncate numeric features\n",
    "\n",
    "\n",
    "    \n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c63bf75",
   "metadata": {},
   "source": [
    "## Building a Model from Scratch\n",
    "The Linear Predictor\n",
    "Why a linear model? Based on our initial data exploration, a simple straight line is a good starting point to model the relationship between a house's size and its price.\n",
    "\n",
    "How it works:\n",
    "The predict function implements the mathematical formula for a line:\n",
    "\n",
    " $\\hat{y} = \\theta_1 \\cdot x + \\theta_0$\n",
    "​\n",
    " \n",
    "\n",
    "Where: $\\hat{y}$ is the predicted price.\n",
    "\n",
    "x is the input feature (sq_mt_built).\n",
    "\n",
    "$\\theta_1$ is the weight (slope), representing the price increase per square meter.\n",
    "\n",
    "$\\theta_0$ is the bias (y-intercept), representing the base price of a house.\n",
    "\n",
    "This function takes an input x and the model parameters theta and returns the model's prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d0d477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the standard RMSE function\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE) from scratch\n",
    "def loss_RMSE(y, yhat):\n",
    "    y = np.array(y)\n",
    "    yhat = np.array(yhat)\n",
    "    diff = y-yhat\n",
    "    squ_diff = diff ** 2\n",
    "    mean = np.mean(squ_diff)\n",
    "    rmse = np.sqrt(mean)\n",
    "    return rmse\n",
    "\n",
    "# Wrapper for the scikit-learn RMSE\n",
    "def loss_RMSE_sk(y, yhat):\n",
    "    return root_mean_squared_error(y, yhat)\n",
    "\n",
    "# Validation test data\n",
    "test_y = [1, 5, 6, 10, 11]\n",
    "test_y_hat = [1.5, 5.7, 6.1, 10.4, 11.2]\n",
    "\n",
    "# Test\n",
    "print(loss_RMSE(test_y, test_y_hat))\n",
    "print(loss_RMSE_sk(test_y, test_y_hat))\n",
    "\n",
    "# find the best fit line\n",
    "m, b = np.polyfit(training_data_x, training_data_y, 1)\n",
    "yhat = m * test_data_x + b\n",
    "\n",
    "print(\"m: \", m,\"b: \", b)\n",
    "\n",
    "print(loss_RMSE(test_data_y, yhat))\n",
    "print(loss_RMSE_sk(test_data_y, yhat))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0548dea",
   "metadata": {},
   "source": [
    "## Implementation of a Linear Predictor\n",
    "Linear Predictor: The predictor function implements the standard linear model equation:  $\\hat{y} = \\theta_1 \\cdot x + \\theta_0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b91956b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, theta):\n",
    "    X_with_bias = np.hstack([np.ones((x.shape[0], 1)), x])\n",
    "    return X_with_bias @ theta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fcd1c6",
   "metadata": {},
   "source": [
    "## Training with Grid Search\n",
    "Why Grid Search? Now that we have a model and a way to measure its error, we need to find the best values for the parameters $\\theta_0$ and $\\theta_1$\n",
    "​\n",
    " . Grid search is an intuitive, brute-force technique for this.\n",
    "\n",
    "How it works:\n",
    "The grid_search function systematically checks every possible combination of $\\theta_0$ and $\\theta_1$\n",
    "​\n",
    "  from a predefined range of values (the \"grid\"). For each pair, it calculates the RMSE on the training data. The function keeps track of the parameter combination that results in the lowest error and returns them as the optimal parameters.\n",
    "\n",
    "We first run it with a coarse grid to find a promising region and then use a finer grid in that region to zero in on a more precise solution, all while keeping the training time under 10 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9663e31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Implement grid search to find the optimal theta_0, theta_1\n",
    "# This is a brute force method that exhaustively checks every parameter combination in a predefined grid\n",
    "def grid_search(training_data_x, training_data_y, grid0, grid1):\n",
    "    best_theta_0 = None\n",
    "    best_theta_1 = None\n",
    "    best_loss = sys.maxsize\n",
    "    for i in grid0:\n",
    "        for j in grid1:\n",
    "            yhat = predict(training_data_x, [i,j])\n",
    "            temp_loss = loss_RMSE_sk(training_data_y, yhat)\n",
    "            if(temp_loss < best_loss):\n",
    "                best_loss = temp_loss\n",
    "                best_theta_0 = i\n",
    "                best_theta_1 = j\n",
    "\n",
    "    return best_theta_0, best_theta_1, best_loss\n",
    "            \n",
    "import time\n",
    "\n",
    "# Define the ranges (grids) of parameters to search through\n",
    "grid0 = np.arange(14000,16000,10)\n",
    "grid1 = np.arange(4000,6000,10)\n",
    "\n",
    "# Time the training process to measure computational cost.\n",
    "start = time.time()\n",
    "theta_0, theta_1, best_loss = grid_search(training_data_x, training_data_y, grid0, grid1)\n",
    "end = time.time()\n",
    "s = (end-start)\n",
    "print(f\"Training Time Elapsed {s} secs.\")\n",
    "\n",
    "print(\"theta_0: \", theta_0, \"theta_1: \", theta_1)\n",
    "\n",
    "# loss on training set\n",
    "print(\"Best train loss: \", best_loss)\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate the model's performance on the unseen test set using the best parameters found via grid seach\n",
    "yhat_test = predict(test_data_x, [theta_0, theta_1])\n",
    "print(\"Test loss is: \", loss_RMSE_sk(test_data_y, yhat_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c46a9f4",
   "metadata": {},
   "source": [
    "## Training with Random Search\n",
    "Why Random Search? Grid search can be computationally expensive, especially if the range of possible parameter values is large. Random search is a more efficient alternative. Instead of trying every single combination, it tests a fixed number of random combinations within the specified range.\n",
    "\n",
    "How it works:\n",
    "The random_search function samples a specified number of trials for θ \n",
    "0\n",
    "​\n",
    "  and θ \n",
    "1\n",
    "​\n",
    "  from a uniform distribution over a given range. It then evaluates the loss for each random pair and returns the best one it found. This approach can often find a very good solution much faster than an exhaustive grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc373403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement a random search to find the optimal model parameters.\n",
    "# This is often more efficient than grid search, as it samples random points in the parameter space\n",
    "# instead of checking every single combination.\n",
    "def random_search(training_data_x, training_data_y, trials):\n",
    "    best_theta_0 = None\n",
    "    best_theta_1 = None\n",
    "    best_loss = sys.maxsize\n",
    "    grid0 = np.random.uniform(15000, 16000, trials)\n",
    "    grid1 = np.random.uniform(4000, 5000, trials)\n",
    "    for i in grid0:\n",
    "        for j in grid1:\n",
    "            yhat = predict(training_data_x, [i,j])\n",
    "            temp_loss = loss_RMSE_sk(training_data_y, yhat)\n",
    "            if(temp_loss < best_loss):\n",
    "                best_loss = temp_loss\n",
    "                best_theta_0 = i\n",
    "                best_theta_1 = j\n",
    "\n",
    "    return best_theta_0, best_theta_1, best_loss\n",
    "\n",
    "\n",
    "# Measure computational cost in seconds\n",
    "start = time.time()\n",
    "\n",
    "# Run the random search with 300 trials for each parameter.\n",
    "theta_0, theta_1, best_loss = random_search(training_data_x, training_data_y, 300)\n",
    "end = time.time()\n",
    "s = (end-start)\n",
    "print(f\"Training Time Elapsed {s} secs.\")\n",
    "\n",
    "print(\"theta_0: \", theta_0, \"theta_1: \", theta_1)\n",
    "\n",
    "# loss on training set\n",
    "print(\"Best train loss is: \", best_loss)\n",
    "\n",
    "#loss on test set\n",
    "yhat_test = predict(test_data_x, [theta_0, theta_1])\n",
    "print(\"Test loss is: \", loss_RMSE_sk(test_data_y, yhat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c0d4e8",
   "metadata": {},
   "source": [
    "## The Industry Standard: Scikit-Learn\n",
    "While building models from scratch is excellent for learning, in a professional setting, we use highly optimized libraries like scikit-learn.\n",
    "\n",
    "Why scikit-learn? It's fast, reliable, and its functions are implemented using efficient, direct analytical methods (like Ordinary Least Squares) rather than brute-force search. This allows it to find the optimal solution almost instantly.\n",
    "\n",
    "How it works:\n",
    "We use the LinearRegression object from sklearn.linear_model. The .fit() method trains the model on the training data, automatically finding the best intercept $\\theta_0$ and coefficient $\\theta_1$. \n",
    "\n",
    "We then use the .predict() method to make predictions on our training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136e4f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the highly-optimized LinearRegression model from scikit-learn.\n",
    "# This represents the industry-standard approach for this type of problem.\n",
    "from sklearn import linear_model\n",
    "def sk_linear_reg(tdx, tdy):\n",
    "    reg_sk = linear_model.LinearRegression()\n",
    "    reg_sk.fit(tdx, tdy)\n",
    "    return reg_sk\n",
    "\n",
    "# Reshape the data from a 1D for SK learn\n",
    "training_data_x_sk = training_data_x.reshape(-1, 1)\n",
    "test_data_x_sk = test_data_x.reshape(-1, 1)\n",
    "\n",
    "# Measure computational cost in seconds\n",
    "start = time.time()\n",
    "reg = sk_linear_reg(training_data_x_sk, training_data_y)\n",
    "end = time.time()\n",
    "s = (end-start)\n",
    "print(f\"Training Time Elapsed {s} secs.\")\n",
    "\n",
    "# The optimal parameters are stored in the .coef_ (slope) and .intercept_ (bias) attributes.\n",
    "print(reg.coef_, reg.intercept_)\n",
    "\n",
    "# Evaluate the final model on both the training and test sets.\n",
    "yhat_train = reg.predict(training_data_x_sk)\n",
    "print(\"train loss is: \", loss_RMSE_sk(training_data_y,yhat_train))\n",
    "yhat_test = reg.predict(test_data_x_sk)\n",
    "print(\"test loss is: \", loss_RMSE_sk(test_data_y,yhat_test))\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a0f077",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Grid Search\n",
    "\n",
    "    Best theta: 4372.100000000044, 15440.0\n",
    "\tTraining Error: 510201.77011160203\n",
    "\tTest Error: 497888.0900697986\n",
    "\tTraining Time: 3.399505138397217 secs\n",
    "\tConclusion: I spent a lot of time fine-tuning grid search to the good values of theta, if I hadn't done this, the algorithm would have been fast but at a cost to accuracy as it would have provided less optimal values of theta. \n",
    " \n",
    "Random Search\n",
    "\t\n",
    " \n",
    "    Best theta: 4374.653091653261, 15000.330159259476,\n",
    "\tTraining Error: 510201.4673081034\n",
    "\tTest Error: 497888.0900697986\n",
    "\tTraining Time: 7.122501850128174 secs\n",
    "\tConclusion: I used a higher value of trial making this algorithm take longer, however, I leveraged the ranges found in grid search which gave me similar accuracy if I hadn't done this it would have been slower and less accurate.\n",
    " \n",
    "Sk Learn\n",
    "\t\n",
    " \n",
    "    Best theta: 4374.46949346, 14798.092112582992\n",
    "\tTraining Error: 510201.4152506144\n",
    "\tTest Error: 497867.84193848644\n",
    "\tTraining Time: 0.0020799636840820312 secs\n",
    "\tConclusion: This algorithm is by the fastest with extreme accuracy with no trial or error for good theta values, if I were to create a linear regression on my own I would use sk learn\n",
    "\n",
    "## Key Takeaways\n",
    "Performance: All three methods found very similar optimal parameters and achieved nearly identical performance on the test set, with an RMSE of approximately 497,867. This indicates that our custom implementations were successful in finding a near-optimal solution. While a RSME of 497, 867 seems high it is an expected outcome for a single-feature model.\n",
    "\n",
    "Speed: The difference in training time is staggering. scikit-learn found the solution in milliseconds, while our search-based methods took several seconds. This highlights the power of using libraries with analytically optimized algorithms.\n",
    "\n",
    "Conclusion: This project demonstrates a solid understanding of the end-to-end machine learning process. Implementing models from scratch provides invaluable insight into the underlying mechanics of training. However, for practical applications, scikit-learn is the clear winner, offering superior speed and guaranteed optimality without the need for manual parameter searching. A professional engineer knows both how the tools work and which one to use for the job.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746f6820",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "house-predictor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
